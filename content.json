{"meta":{"title":"JevonYang的博客","subtitle":"","description":"Be a better coder!","author":"JevonYang","url":"https://jevonyang.github.io","root":"/"},"pages":[{"title":"Hello World","date":"2021-10-22T02:22:56.176Z","updated":"2021-10-22T02:22:56.176Z","comments":true,"path":"hello-world.html","permalink":"https://jevonyang.github.io/hello-world.html","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment"}],"posts":[{"title":"Flink部署简单介绍","slug":"Flink部署简单介绍","date":"2021-01-23T11:09:54.000Z","updated":"2021-10-22T02:22:56.176Z","comments":true,"path":"2021/01/23/Flink部署简单介绍/","link":"","permalink":"https://jevonyang.github.io/2021/01/23/Flink%E9%83%A8%E7%BD%B2%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"近两年Flink作为批流一体代表异军突起，成为大数据领域数据计算框架的佼佼者；同时kubernetes作为目前最为主流硬件资源调度框架，大数据也不断向其靠拢，大数据 on kubernetes也逐渐成为部署的主流或方向。以下我们来介绍一下，flink的两种简单的部署方式，standalone和native kubernetes部署 部署方式目前部署方式为flink on native kubernetes的方式部署，之前是通过flink standalone方式部署，两者方式都较为简单，kubernetes的方式更为推荐。 standalone部署文档： https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/deployment/cluster_setup.html 下载地址：https://flink.apache.org/downloads.html 这里简述flink的部署方式，在目标主机上下载对应flink版本（目前我们使用的是1.11.1），并解压。解压后，进入flink目录，执行./bin/start-cluster.sh即可运行，在 http://localhost:8081，即可看到flink ui（如下图所示），如果是想在windows，在WSL中同样可以运行该命令。 通过SubmitNewJob -&gt; Add new -&gt; 填写Entry Class入口类 -&gt; submit，即可提交任务。 中间有两个概念，Job Manager、TaskManager: Job Manager像是总指挥，如果提交后有什么编译错误，会在Job Manager里的log里打印出来。 TaskManager是具体执行者，在执行过程中有什么输出结果，或者执行过程中的错误，会在TaskManager的log打印出来，根据相应问题就可以具体排查错误了。 kuberneteskubernetes用起来真的很快乐，真正做到资源池化，资源的隔离，并且很方便的通过docker复用，很大程度上实现了build once, run anywhere。 Native Kubernetes 官方文档：https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/deployment/native_kubernetes.html 部署命令其部署也很简单，解压后，进入flink目录，命令如下： 123456789101112./bin/flink run-application -p 8 -t kubernetes-application -c com.yang.flink.JavaStreamingJob -Dkubernetes.cluster-id=your-flink-job-id -Dkubernetes.jobmanager.service-account=flink -Dtaskmanager.memory.process.size=4096m -Dkubernetes.taskmanager.cpu=2 -Dtaskmanager.numberOfTaskSlots=4 -Dkubernetes.rest-service.exposed.type=NodePort # 使用NodePort暴露端口，每次部署之后，其暴露端口会不同 -Dkubernetes.config.file=/opt/flink-1.11.1/bin/config # 如果不指定kubernetes.config文件会默认去~/.kube/config中找 -Dkubernetes.container.image=your/docker-registry/your-flink-docker-image:your-tag local:///opt/flink/usrlib/app.jar 其中有一个重要参数强调一下： 指定入口类entry class: -c com.yang.flink.JavaStreamingJob，如果没有，会有一个在pom.xml中定义的默认值 kubernetes的service-acount： -Dkubernetes.jobmanager.service-account=spark，在这里声明了，并且需要提前在kubernetes中创建。12kubectl create clusterrolebinding flink-role-binding-default --clusterrole=edit --serviceaccount=default:default# 这里创建的是default的权限，根据自己需要创建用户 kubernetes ui暴露：-Dkubernetes.rest-service.exposed.type=NodePort，我们是通过NodePort暴露的，每次暴露出的端口会不同，默认是lb暴露 kubernetes目标地址及秘钥： 通过-Dkubernetes.config.file参数指定kubernetes的地址、秘钥，如果没有，默认值为~/.kube/config docker镜像：Dkubernetes.container.image，指定需要部署的镜像，并且kubernetes可以获取到即可 指定docker镜像中jar路径：local:///opt/flink/usrlib/app.jar,根据dockerfile中的内容定义。 docker镜像打包以下Dockerfile根据官网提供改写而来： 1234FROM flink:1.11.1-scala_2.11-java8RUN mkdir -p $FLINK_HOME/usrlibRUN /bin/cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; echo &#x27;Asia/Shanghai&#x27; &gt;/etc/timezoneADD target/your-jar.jar $FLINK_HOME/usrlib/app.jar 说几个点： 基础镜像dockerhub上有，根据需要的版本选择即可。 增加了时区的设置，避免时区错误，差八个小时的问题。 jenkins部署flink on native kubernetes大家可以通过本机WSL，只要可以连接内网的kubernetes，通过以上命令即可部署。 为了进步方便部署，还可以部署一套jenkins和flink进行部署。 我在上面设置了job，当提交新任务的时候注意一下几点： -c com.yang.flink.JavaStreamingJob入口类是否正确， -Dkubernetes.container.image中镜像的名称和tag是否正确 123456789101112131415node (&#x27;master&#x27;)&#123; stage(&quot;Job submit&quot;)&#123; sh &quot;/opt/flink-1.11.1/bin/flink run-application -p 8 -t kubernetes-application -c com.yang.flink.JavaStreamingJob&quot; + &quot; -Dkubernetes.cluster-id=your-flink-job-id&quot; + &quot; -Dkubernetes.jobmanager.service-account=flink&quot; + &quot; -Dtaskmanager.memory.process.size=4096m&quot; + &quot; -Dkubernetes.taskmanager.cpu=2&quot; + &quot; -Dtaskmanager.numberOfTaskSlots=4&quot; + &quot; -Dkubernetes.rest-service.exposed.type=NodePort&quot; + &quot; -Dkubernetes.config.file=/opt/flink-1.11.1/bin/config&quot; + &quot; -Dkubernetes.container.image=your/docker-registry/your-flink-docker-image:your-tag&quot;+ &quot; local:///opt/flink/usrlib/app.jar&quot; &#125;&#125; 如果提交错误，可以直接在kubernetes中停止该任务，也可以通过kubernetes暴露出的端口，进入flink ui，cancel job,相应的容器会自动销毁。 Enjoy flink! Good Luck!","categories":[],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://jevonyang.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}]},{"title":"在SpringWebFlux使用缓存","slug":"[Reactive]在SpringWebFlux使用缓存","date":"2020-09-21T07:37:58.000Z","updated":"2021-10-22T02:22:56.176Z","comments":true,"path":"2020/09/21/[Reactive]在SpringWebFlux使用缓存/","link":"","permalink":"https://jevonyang.github.io/2020/09/21/[Reactive]%E5%9C%A8SpringWebFlux%E4%BD%BF%E7%94%A8%E7%BC%93%E5%AD%98/","excerpt":"","text":"Project Reactor中的Cache对象虽然reactor-netty使用nio的方式读写数据源大大加快了程序的响应速度，但是无论使用什么方法，远程数据读写都无法追赶上本地缓存的速度。 Project Reactor也提供了Cache的接入手段。在加入以下依赖，即可使用缓存对象: 123456&lt;!-- https://mvnrepository.com/artifact/io.projectreactor.addons/reactor-extra --&gt;&lt;dependency&gt; &lt;groupId&gt;io.projectreactor.addons&lt;/groupId&gt; &lt;artifactId&gt;reactor-extra&lt;/artifactId&gt; &lt;version&gt;3.3.4.RELEASE&lt;/version&gt;&lt;/dependency&gt; CacheMono CacheFlux 从名字上可以看出，CacheMono和Mono相对，代表[0..1]的对象，CacheFlux和Flux相对，代表[0..N]的对象。 事实上,在Spring Cloud Gateway源码中，就使用到了CacheFlux，用于缓存路由信息。 12345public CachingRouteDefinitionLocator(RouteDefinitionLocator delegate) &#123; this.delegate = delegate; routeDefinitions = CacheFlux.lookup(cache, &quot;routeDefs&quot;, RouteDefinition.class) .onCacheMissResume(this.delegate::getRouteDefinitions); &#125; CacheFlux官方文档例子官方一下两个例子，一个是Generic cache entry points，另一个是Map endpoints Generic cache entry points1234567891011121314AtomicReference&lt;Context&gt; storeRef = new AtomicReference&lt;&gt;(Context.empty()); Flux&lt;Integer&gt; cachedFlux = CacheFlux .lookup(k -&gt; Mono.justOrEmpty(storeRef.get().getOrEmpty(k)) .cast(Integer.class) .flatMap(max -&gt; Flux.range(1, max) .materialize() .collectList()), key) .onCacheMissResume(Flux.range(1, 10)) .andWriteWith((k, sigs) -&gt; Flux.fromIterable(sigs) .dematerialize() .last() .doOnNext(max -&gt; storeRef.updateAndGet(ctx -&gt; ctx.put(k, max))) .then()); Map endpoints1234567891011String key = &quot;myCategory&quot;;LoadingCache&lt;String, Object&gt; graphs = Caffeine .newBuilder() .maximumSize(10_000) .expireAfterWrite(5, TimeUnit.MINUTES) .refreshAfterWrite(1, TimeUnit.MINUTES) .build(key -&gt; createExpensiveGraph(key));Flux&lt;Integer&gt; cachedMyCategory = CacheFlux .lookup(graphs.asMap(), key, Integer.class) .onCacheMissResume(repository.findAllByCategory(key)); 我们以Map endpoints的例子说明。 在上面Map endpoints的例子上可以看到,使用了Caffeine缓存，这里也可以换成Guava Cache或者ConcurrentHashMap甚至Hashmap，使用Hashmap的时候，取决并发逻辑，尤其在写缓存的时候。 代码逻辑很简单，通过lookUp方法查找缓存，如果没有找到，通过onCacheMissResume方法查找数据源。 遇到的问题在定义了LoadingCache，我希望使用refresh(key)的方式更新缓存，但是发生问题。下面是我使用的LoadingCache.build()方法定义的内容。 123456.build(new CacheLoader&lt;String, Object&gt;() &#123; @Override public YourType load(String key) throws Exception &#123; return getYourTypeValue(key); // 同步代码 &#125;&#125;) 但是在刷新缓存后，再使用CacheFlux则会报错: 1Content of cache for key xxx cannot be cast to List&lt;Signal&gt; 说一个不成熟的结论： 不能通过refresh()方法来刷新缓存 为什么会这样？我们接下来看一这一块的源码是如何写的。 源码解析1234567891011121314151617181920212223242526public static &lt;KEY, VALUE&gt; FluxCacheBuilderMapMiss&lt;VALUE&gt; lookup(Map&lt;KEY, ? super List&gt; cacheMap, KEY key, Class&lt;VALUE&gt; valueClass) &#123; return otherSupplier -&gt; Flux.defer(() -&gt; &#123; Object fromCache = cacheMap.get(key); if (fromCache == null) &#123; return otherSupplier.get() .materialize() .collectList() .doOnNext(signals -&gt; cacheMap.put(key, signals)) .flatMapIterable(Function.identity()) .dematerialize(); &#125; else if (fromCache instanceof List) &#123; try &#123; @SuppressWarnings(&quot;unchecked&quot;) List&lt;Signal&lt;VALUE&gt;&gt; fromCacheSignals = (List&lt;Signal&lt;VALUE&gt;&gt;) fromCache; return Flux.fromIterable(fromCacheSignals) .dematerialize(); &#125; catch (Throwable cause) &#123; return Flux.error(new IllegalArgumentException(&quot;Content of cache for key &quot; + key + &quot; cannot be cast to List&lt;Signal&gt;&quot;, cause)); &#125; &#125; else &#123; return Flux.error(new IllegalArgumentException(&quot;Content of cache for key &quot; + key + &quot; is not a List&quot;)); &#125; &#125;);&#125; 上面的逻辑比较简单，其中otherSupplier实际上指的是onCacheMissResume方法中的参数；Flux.defer顾名思义，延迟加载，当需要的时候才进行加载。 首先，代码从cacheMap中拿到key对应的缓存内容，接下来就是进行判断，如果没有，则通过otherSupplier去读取数据源。 12345678if (fromCache == null) &#123; return otherSupplier.get() .materialize() .collectList() .doOnNext(signals -&gt; cacheMap.put(key, signals)) .flatMapIterable(Function.identity()) .dematerialize();&#125; 其中有三个细节，一个是materialize方法，将对应数据具象化。我们知道，在reactive中Flux和Mono各种操作符，只是对数据做操作的描述，而不是数据对象本身，我们不能将操作符做缓存。做一个比方，我们各种操作符就相当于管道，而数据通过管道做对应的操作，最后形成所需要的内容，而所需要的内容被subscibe()方法消费，而真正的被消费的对象（或者说数据）则是源头对象中的subscription。 123public final Flux&lt;Signal&lt;T&gt;&gt; materialize() &#123; return onAssembly(new FluxMaterialize&lt;&gt;(this));&#125; 通过materialize我们将数据转换成Signal&lt;T&gt;，而这个Singal里则包含我们所需要消费的数据，即可作为消费的数据来源。 另外一个细节在doOnNext方法中,拿到signals对象后,将数据放回cacheMap中，所以我们无需在代码中显式的将数据插入缓存。 1.doOnNext(signals -&gt; cacheMap.put(key, signals)) 第三个，则是dematerialize()，显然该方法与materialize()相对，是将将Signal&lt;T&gt;转换成T,进而进行下一步的操作或者消费。 12345public final &lt;X&gt; Flux&lt;X&gt; dematerialize() &#123; @SuppressWarnings(&quot;unchecked&quot;) Flux&lt;Signal&lt;X&gt;&gt; thiz = (Flux&lt;Signal&lt;X&gt;&gt;) this; return onAssembly(new FluxDematerialize&lt;&gt;(thiz));&#125; 从中我们发现Singal是一个容器，用于存放实际数据数据。 接下来，我们来看如果在cacheMap中能够拿到key对应的缓存内容。如果是拿到的缓存是List对象，则进行类型转换，将Signal&lt;T&gt;转换成T，即dematerialize()。 1234567else if (fromCache instanceof List) &#123; try &#123; @SuppressWarnings(&quot;unchecked&quot;) List&lt;Signal&lt;VALUE&gt;&gt; fromCacheSignals = (List&lt;Signal&lt;VALUE&gt;&gt;) fromCache; return Flux.fromIterable(fromCacheSignals) .dematerialize(); &#125; 看到这里我们就知道为什么通过直接缓存刷新之后，再使用缓存会报错？在刷新的代码中，直接将缓存类型T放入缓存，而不是Signal&lt;T&gt;，当再次使用缓存时候，自然不能做类型转换(List&lt;Signal&lt;VALUE&gt;&gt;) fromCache，于是报出类型转换错误。 123456.build(new CacheLoader&lt;String, Object&gt;() &#123; @Override public YourType load(String key) throws Exception &#123; return getYourTypeValue(key); // 同步代码 &#125;&#125;) 总结123451. cacheMap查询 -&gt; 如果没有 -&gt; 通过 onCacheMissResume中参数的方法查询数据 -&gt; 通过materialize()方法将数据具象化，把T转换为Signal&lt;T&gt; -&gt; 写入缓存map -&gt; 通过dematerialize()方法，反具象化，把Sinal&lt;T&gt;转T -&gt; 交给下步使用2. cacheMap查询 -&gt; 如果有 -&gt; 通过dematerialize()方法，反具象化，把Sinal&lt;T&gt;转T -&gt; 交给下步使用 如何改进？（课后题 :D）从上面的代码分析我们可以看到，缓存中存放的是Singal&lt;T&gt;，所以我们需要将T转换成Singal&lt;T&gt;放入缓存。 123456.build(new CacheLoader&lt;String, Object&gt;() &#123; @Override public YourType load(String key) throws Exception &#123; return Signal.next(getYourTypeValue(key)); // 同步代码 &#125;&#125;) 通过Signal.next(getYourTypeValue(key))这样的方法，放入缓存后是否可用，待各位读者自行验证。","categories":[],"tags":[{"name":"reactive, spring webflux","slug":"reactive-spring-webflux","permalink":"https://jevonyang.github.io/tags/reactive-spring-webflux/"}]},{"title":"Java如何实现一个回调地狱（Callback Hell）？","slug":"Java如何实现一个回调地狱（Callback Hell）？","date":"2019-09-20T09:58:58.000Z","updated":"2021-10-22T02:22:56.176Z","comments":true,"path":"2019/09/20/Java如何实现一个回调地狱（Callback Hell）？/","link":"","permalink":"https://jevonyang.github.io/2019/09/20/Java%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E5%9B%9E%E8%B0%83%E5%9C%B0%E7%8B%B1%EF%BC%88Callback%20Hell%EF%BC%89%EF%BC%9F/","excerpt":"","text":"对于回调地狱（Callback hell），想必大家都不陌生，尤其对于前端的朋友，当然前端的朋友通过各种办法去避免回调地狱，比如Promise。但是对于后端的朋友，尤其在RxJava、Reactor等反应式编程框架兴起之后，对于回调地狱只是听得多，但是见得的少。 为了更好了解回调地狱Callback hell问题在哪，我们首先需要学会怎么写出一个回调地狱。在之前，我们得知道什么是回调函数。 本文将包含： 什么是回调 回调的优势 回调地狱是什么 为什么会出现回调地狱 回调和Future有什么区别 如何解决回调地狱 我们今天从最开始讲起，先讲讲什么是回调函数。 什么是回调函数？在百度百科上，是这么说的： 回调函数就是一个通过函数指针调用的函数。如果你把函数的指针（地址）作为参数传递给另一个函数，当这个指针被用来调用其所指向的函数时，我们就说这是回调函数。回调函数不是由该函数的实现方直接调用，而是在特定的事件或条件发生时由另外的一方调用的，用于对该事件或条件进行响应。 回调是任何一个被以方法为其第一个参数的其它方法的调用的方法。很多时候，回调是一个当某些事件发生时被调用的方法。 什么？不好理解？确实很难理解，并且这段解释还有指针云云，对于java用户实在是不友好。 给大家举个例子，供大家参考，也欢迎批评指正： 回调：调用方在调用被调方后，被调方还将结果反馈给调用方。（A调用B，B完成后，将结果反馈给A） 举个例子：老板安排员工一项工作，员工去完成。员工完成工作后，给老板反馈工作结果。这个过程就叫回调。 这下容易理解很多了吧！Talk is cheap, Show me the code! 好，我们就用这个写一个简单的例子。 回调的例子Callback接口首先，我们先写一个如下的Callback接口，接口只包含一个方法，用于callback操作。 123456789101112/** * @author yangzijing */public interface Callback&lt;T&gt; &#123; /** * 具体实现 * @param t */ public void callback(T t);&#125; Boss类老板是被反馈的对象，于是需要实现Callback这个接口，重载callback方法；对于老板具体要干什么，当然是做大生意，于是有了makeBigDeals方法；老板当然不能是光杆司令，他需要一个员工，我们再构造方法里给他添加一个员工Worker，稍后我们来实现Worker类。 1234567891011121314151617public class Boss implements Callback&lt;String&gt; &#123; private Worker worker; public Boss(Worker worker) &#123; this.worker = worker; &#125; @Override public void callback(String s) &#123; &#125; public void makeBigDeals(final String someDetail) &#123; worker.work(someDetail); &#125;&#125; Worker类员工类，很简单，出入一个工作，完成就好了，返回结果即可。但是如何完成回调？ 12345public class Worker &#123; public String work(String someWork) &#123; return &#x27;result&#x27;; &#125;&#125; 我们很容易想到就是这个思路，非常符合思维的逻辑，但是在回调中，我们需要做一些改变。 让代码回调起来对于员工来说，需要知道两点，谁是老板，需要干啥。于是，输入两个参数，分别是老板和工作内容。具体内容分两步，首先完成任务，之后则是汇报给老板。 123456public class Worker &#123; public void work(Callback&lt;String&gt; boss, String someWork) &#123; String result = someWork + &#x27;is done!&#x27;; // 做一些具体的处理 boss.callback(result); // 反馈结果给老板 &#125;&#125; 接下来，我们完成Boss类。在callback方法中，接收到传来的结果，并对结果进行处理，我们这里仅打印出来；在makeBigDeals方法中，老板分配工作，员工去完成，如果完成过程是异步，则是异步调用，如果是同步的，则是同步回调，我们这里采用异步方式。 在新建线程中，我们执行worker.work(Boss.this, someDetail)，其中Boss.this即为当前对象，在这里，我们正式完成了回调。 1234567891011121314public class Boss implements Callback&lt;String&gt; &#123; …… @Override public void callback(String result) &#123; // 参数为worker输出的结果 logger.info(&quot;Boss got: &#123;&#125;&quot;, result) // 接到完成的结果，并做处理，在这里我们仅打印出来 &#125; public void makeBigDeals(final String someDetail) &#123; logger.info(&quot;分配工作&quot;); new Thread(() -&gt; worker.work(Boss.this, someDetail)); // 异步完成任务 logger.info(&quot;分配完成&quot;); logger.info(&quot;老板下班。。&quot;); &#125;&#125; 回调结果Show me the result! 好，跑一下代码试一下。 123Worker worker = new Worker();Boss boss = new Boss(worker); // 给老板指派员工boss.makeBigDeals(&quot;coding&quot;); // 老板有一个代码要写 结果如下。在结果中可以看到，老板在分配完工作后就下班了，在下班后，另一个线程通知老板收到反馈”coding is done”。至此，我们完成了异步回调整个过程。 1234INFO 2019 九月 20 11:30:54,780 [main] - 分配工作 INFO 2019 九月 20 11:30:54,784 [main] - 分配完成 INFO 2019 九月 20 11:30:54,784 [main] - 老板下班。。 INFO 2019 九月 20 11:30:54,787 [Thread-0] - Boss got: coding is done! 我将代码示例传至Github，供大家参考。 callback代码示例 回调的优势 解耦，回调将子过程从主过程中解耦。 对于相同的输入，可能对其有不同的处理方式。在回调函数，我们完成主流程（例如上面的Boss类），对于过程中的子流程（例如上面的Worker类）从主流程中分离出来。对于主流程，我们只关心子过程的输入和输出，输入在上面的例子中即为Worker.work中的参数，而子过程的输出则是主过程的callback方法的参数。 异步回调不会阻塞主线程。上面的例子清晰可以看到，员工没有完成工作之前老板就已经下班，当工作完成后，会通过另一个线程通知老板。老板在这个过程无需等待子过程。 回调地狱总体设计 我们将上述功能扩展，老板先将工作交给产品经理进行设计；设计完成后，交给程序员完成编码。流程示意如图。 将任务交给产品经理首先，写一个Callback，内部new一个产品经理的的Worker，在makeBigDeal方法实现主任务，将任务交给产品经理；在重载的callback方法中，获取产品经理的输出。 1234567891011121314new Callback&lt;String&gt;() &#123; private Worker productManager = new Worker(); @Override public void callback(String s) &#123; System.out.println(&quot;产品经理 output: &quot; + s); // 获取产品经理的输出 &#125; public void makeBigDeals(String bigDeal) &#123; System.out.println(&quot;Boss将任务交给产品&quot;); new Thread(() -&gt; &#123; this.productManager.work(this, bigDeal); // 异步调用产品经理处理过程 &#125;).start(); &#125; &#125;.makeBigDeals(&quot;design&quot;); 再将产品经理输出交给开发在拿到产品经理的输出之后，再将输出交给开发。于是我们在再次实现一个Callback接口。同样的，在Callback中，new一个开发的Worker，在coding方法中，调用Worker进行开发；在重载的callback方法中，获取开发处理后的结果。 123456789101112131415161718@Overridepublic void callback(String s) &#123; System.out.println(&quot;产品经理 output: &quot; + s); // 产品经理的输出 String midResult = s + &quot; coding&quot;; System.out.println(&quot;产品经理设计完成，再将任务交给开发&quot;); new Callback&lt;String&gt;() &#123; private Worker coder = new Worker(); @Override public void callback(String s) &#123; System.out.println(&quot;result： &quot; + s); // 获取开发后的结果 &#125; public void coding(String coding) &#123; new Thread(() -&gt; coder.work(this, coding)).start(); // 调用开发的Worker进行开发 &#125; &#125;.coding(midResult); // 将产品经理的输出交给开发&#125; 完整的实现123456789101112131415161718192021222324new Callback&lt;String&gt;() &#123; private Worker productManager = new Worker(); @Override public void apply(String s) &#123; System.out.println(&quot;产品经理 output: &quot; + s); String midResult = s + &quot; coding&quot;; System.out.println(&quot;产品经理设计完成，再将任务交给开发&quot;); new Callback&lt;String&gt;() &#123; private Worker coder = new Worker(); @Override public void apply(String s) &#123; System.out.println(&quot;result： &quot; + s); &#125; public void coding(String coding) &#123; new Thread(() -&gt; coder.work(this, coding)).start(); &#125; &#125;.coding(midResult); &#125; public void makeBigDeals(String bigDeal) &#123; System.out.println(&quot;Boss将任务交给产品&quot;); new Thread(() -&gt; this.productManager.work(this, bigDeal)).start(); &#125; &#125;.makeBigDeals(&quot;design&quot;); 好了，一个简单的回调地狱完成了。Show me the result! 1234Boss将任务交给产品产品经理 output: design is done!产品经理设计完成，再将任务交给开发result： design is done! coding is done! 回调地狱带来了什么？到底什么是回调地狱？简单的说，回调地狱就是Callback里面又套了一个Callback，但是如果嵌套层数过多，仿佛掉入地狱，于是有了回调地狱的说法。 优势： 回调地狱给我们带来什么？事实上，回调的代码如同管道一样，接收输入，并将处理后的内容输出至下一步。而回调地狱，则是多个管道连接，形成的一个流程，而各个子流程（管道）相互独立。前端的朋友可能会更熟悉一些，例如Promise.then().then().then(),则是多个处理管道形成的流程。 劣势： 回调的方法虽然将子过程解耦，但是回调代码的可读性降低、复杂性大大增加。 Callback Hell示例：Callback Hell 和Future对比在上面，我们提到异步回调不会阻塞主线程，那么使用Future也不会阻塞，和异步回调的差别在哪？ 我们写一个使用Future来异步调用的示例： 12345logger.info(&quot;分配工作...&quot;);CompletableFuture&lt;String&gt; future = CompletableFuture.supplyAsync(() -&gt; worker.work(someDetail));logger.info(&quot;分配完工作。&quot;);logger.info(&quot;老板下班回家了。。。&quot;);logger.info(&quot;boss got the feedback from worker: &#123;&#125;&quot;, future.get()); 在上面的代码，我们可以看到，虽然Worker工作是异步的，但是老板获取工作的结果（future.get()）的时候却需要等待，而这个等待的过程是阻塞的。这是回调和Future一个显著的区别。 回调和Future的对比： callback和future对比 如何解决如何解决回调地狱的问题，最常用的就是反应式编程RxJava和Reactor，还有Kotlin的Coroutine协程，OpenJDK搞的Project Loom。其中各有优势，按下不表。 总结总结一下： 什么是回调。回调是调用方在调用被调方后，被调方还将结果反馈给调用方。（A调用B，B完成后，将结果反馈给A） 回调的优势。1）子过程和主过程解耦。2）异步调用并且不会阻塞主线程。 回调地狱是什么。回调地狱是回调函数多层嵌套，多到看不清=。= 为什么会出现回调地狱。每一个回调像一个管道，接受输出，处理后将结果输出到下一管道。各个管道处理过程独立，多个管道组成整个处理过程。 回调和Future有什么区别。1）两者机制不同；2）Future在等待结果时会阻塞，而回调不会阻塞。 如何解决回调地狱。最常见的则是反应式编程RxJava和Reactor。","categories":[],"tags":[{"name":"callback","slug":"callback","permalink":"https://jevonyang.github.io/tags/callback/"}]},{"title":"Java8遍历Map的三种方式——for/stream/forEach","slug":"Java8遍历Map的三种方式——for-stream-forEach","date":"2019-08-28T06:22:58.000Z","updated":"2021-10-22T02:22:56.176Z","comments":true,"path":"2019/08/28/Java8遍历Map的三种方式——for-stream-forEach/","link":"","permalink":"https://jevonyang.github.io/2019/08/28/Java8%E9%81%8D%E5%8E%86Map%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F%E2%80%94%E2%80%94for-stream-forEach/","excerpt":"","text":"最近写在基于Spring WebFlux项目遇到一个需求，希望将请求中的cookie/headers/params等信息获取，而获取后的数据结构都是MultiValueMap&lt;K, V&gt;的数据结构，实质上可以看做是Map&lt;K, List&lt;V&gt;&gt;这种数据结构。而我需要将其转换。 for循环遍历Show me the code first!以下是代码，解释一下逻辑，原来的cookies数据结构为Map&lt;String, List&lt;HttpCookie&gt;&gt;,其中HttpCookie为cookie键值对，由于业务需要，我们需要将其转换成Map&lt;String, String&gt;才更方便处理，于是乎就有了以下代码。（我这里直接用了foreach循环，也可以用fori循环，例如for(int i = 0; i&lt; xx; i++)） 1234567891011MultiValueMap&lt;String, HttpCookie&gt; cookies = request.getCookies(); // 从request中获取原始的cookieMap&lt;String, String&gt; cookieMap = new HashMap&lt;&gt;(); // 新建一个map，将cookie转入该map中for (Map.Entry&lt;String, List&lt;HttpCookie&gt;&gt; itemList : cookies.entrySet()) &#123; // 遍历原始的MultiValueMap for (HttpCookie item :itemList.getValue()) &#123; // 遍历每个item中的List&lt;HttpCookie&gt;，其中的HttpCookie是我们需要的内容 cookieMap.put(item.getName(), item.getValue()); // 存入内容 &#125;&#125; stream流的方式处理在Java8中，我们可以使用流，将Collections或者数组转化成Stream，并用链式的调用更加逻辑更加清晰。 12345678MultiValueMap&lt;String, HttpCookie&gt; cookies = request.getCookies();Map&lt;String, String&gt; cookieMap = new HashMap&lt;&gt;();cookies.entrySet() // 获取entrySet .stream() // 将其转化成流 .map(Map.Entry&lt;String, List&lt;HttpCookie&gt;&gt;::getValue) // MultiValueMap&lt;String, HttpCookie&gt; -&gt; List&lt;HttpCookie&gt; .flatMap(List&lt;HttpCookie&gt;::stream) // List&lt;HttpCookie&gt; -&gt; HttpCookie .forEach(cookie -&gt; cookieMap.put(cookie.getName(), cookie.getValue())); // 遍历，存入内容 Collection具有的forEach方法遍历继续用Stream处理我们可以看到通过流的方法处理cookie的方法，接下来，我们接着用相同的方法来处理请求参数，请求参数原本的数据格式依然为MultiValueMap&lt;String, String&gt;，可以看做是Map&lt;String, List&lt;String&gt;&gt;，其中请求参数名（key）对应的值（value）可能为多行，我们需要将其处理成一行。 12345678910MultiValueMap&lt;String, String&gt; params = request.getQueryParams();Map&lt;String, String&gt; paramMap = new HashMap&lt;&gt;();params.entrySet() .stream() // 将Set转换为Stream .forEach(entry -&gt; paramMap.put( entry.getKey(), // 将参数名写入Key entry.getValue().stream().collect(Collectors.joining())) // 参数值多行合并成一行写入value ); 大家可以看到，在处理参数值（value）的时候，值为List&lt;String&gt;数据结构，以上代码通过entry.getValue().stream().collect(Collectors.joining()))将其List先转化为Stream，再用流的collection方法，将其合并。这个Collectors还具有将toSet/toList/groupingBy等功能，大家可以自行研究，这里就是使用的是joining合并方法。 存在优化点写完后，我发现IntelliJ IDEA给我提示，显示我的代码‘不优雅’，还可以改进。IDE会对有改进空间的代码标黄，下图即为提示内容。 图一，事实上在Java8中Collection可以直接使用foreach的方法，无需转成stream再使用foreach方法。 图二，Java8增强了String的方法，可以直接使用String.join合并List&lt;String&gt;,第一个参数为连接字符串的字符，我这里用的是空格&quot; &quot;，第二个参数是待连接的字符串集合。 使用Collection的forEach方法遍历Map修改后的代码如下： 1params.forEach((key, value) -&gt; paramMap.put(key, String.join(&quot; &quot;, value))); 这个时候我就想，为什么在处理例2（处理cookie的例子）的时候没有让我直接使用Collection.forEach？因为处理这个的例子相对复杂，使用了流的map/flatMap等方法。 总结此时我们可以看到流的遍历Map和Collection.forEach遍历Map的区别（事实上Collection数据结构都可以使用以上方法）： 流的方法更加灵活，根据业务需要可以使用map/flatMap/filter/reduce等更复杂的操作。 collection.forEach相对简单，处理简单的逻辑，干净利落，不拖泥带水。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://jevonyang.github.io/tags/java/"}]},{"title":"Spring Security原理介绍、源码解析——授权过程","slug":"Spring Security原理介绍、源码解析——授权过程","date":"2019-04-17T07:05:58.000Z","updated":"2021-10-22T02:22:56.176Z","comments":true,"path":"2019/04/17/Spring Security原理介绍、源码解析——授权过程/","link":"","permalink":"https://jevonyang.github.io/2019/04/17/Spring%20Security%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D%E3%80%81%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E2%80%94%E2%80%94%E6%8E%88%E6%9D%83%E8%BF%87%E7%A8%8B/","excerpt":"","text":"流程简述当我们成功登录，获取access_token，即可使用该token来访问有权限的接口。如上文所讲，JwtAuthenticationFilter将access_token转化为系统可识别的Authentication放入安全上下文，则来到最后一个过滤器FilterSecurityInterceptor,该过滤则是判断请求是否拥有权限。 12345678910111213141516171819202122232425262728293031323334public class FilterSecurityInterceptor extends AbstractSecurityInterceptor implements Filter &#123; public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; FilterInvocation fi = new FilterInvocation(request, response, chain); invoke(fi); &#125; public void invoke(FilterInvocation fi) throws IOException, ServletException &#123; if ((fi.getRequest() != null) &amp;&amp; (fi.getRequest().getAttribute(FILTER_APPLIED) != null) &amp;&amp; observeOncePerRequest) &#123; // filter already applied to this request and user wants us to observe // once-per-request handling, so don&#x27;t re-do security checking fi.getChain().doFilter(fi.getRequest(), fi.getResponse()); &#125; else &#123; // first time this request being called, so perform security checking if (fi.getRequest() != null &amp;&amp; observeOncePerRequest) &#123; fi.getRequest().setAttribute(FILTER_APPLIED, Boolean.TRUE); &#125; // 请求之前的工作，也就是真正的权限认证的过程 InterceptorStatusToken token = super.beforeInvocation(fi); try &#123; // 请求真正的controller fi.getChain().doFilter(fi.getRequest(), fi.getResponse()); &#125; finally &#123; super.finallyInvocation(token); &#125; // 请求后的工作 super.afterInvocation(token, null); &#125; &#125;&#125; FilterSecurityInterceptor的主体方法依旧在doFilter中，而其中主要的方法为invoke()，大约分为三个步骤： beforeInvocation(fi); 验证Context中的Authentication和目标url所需权限是否匹配，匹配则通过，不通过则抛出异常。 fi.getChain().doFilter(fi.getRequest(), fi.getResponse()); 在此可以看做是，真正去访问目标Controller。 afterInvocation(token, null); 获取请求后的操作。 首先来看看beforeInvocation() beforeInvocation123456789101112131415161718192021222324252627282930313233343536abstract class AbstractSecurityInterceptor &#123; protected InterceptorStatusToken beforeInvocation(Object object) &#123; // 获取目标url的权限内容，这些内容可以从configuration中获取也可以用MetadataSource中获取 Collection&lt;ConfigAttribute&gt; attributes = this.obtainSecurityMetadataSource().getAttributes(object); // ……省略 Authentication authenticated = authenticateIfRequired(); // Attempt authorization try &#123; // AccessDecisionManager用于验证Authentication中的权限和目标url所需权限是否匹配，如果不匹配则抛出AccessDeniedException异常 this.accessDecisionManager.decide(authenticated, object, attributes); &#125; catch (AccessDeniedException accessDeniedException) &#123; publishEvent(new AuthorizationFailureEvent(object, attributes, authenticated, accessDeniedException)); throw accessDeniedException; &#125; // Attempt to run as a different user Authentication runAs = this.runAsManager.buildRunAs(authenticated, object, attributes); // 下一步则是生成InterceptorStatusToken，用于AfterInvocation步骤。有兴趣可以自己看 if (runAs == null) &#123; // no further work post-invocation return new InterceptorStatusToken(SecurityContextHolder.getContext(), false, attributes, object); &#125; else &#123; SecurityContext origCtx = SecurityContextHolder.getContext(); SecurityContextHolder.setContext(SecurityContextHolder.createEmptyContext()); SecurityContextHolder.getContext().setAuthentication(runAs); // need to revert to token.Authenticated post-invocation return new InterceptorStatusToken(origCtx, true, attributes, object); &#125; &#125;&#125; Collection&lt;ConfigAttribute&gt; attributes = this.obtainSecurityMetadataSource().getAttributes(object);获取目标url所需要的权限，该类实现FilterInvocationSecurityMetadataSource接口的方法。而配置url权限也可以从WebSecurityConfig中的configuration方法配置。 this.accessDecisionManager.decide(authenticated, object, attributes);判断Authentication中的权限目标url所需权限是否匹配，匹配则通过；不匹配则抛出AccessDeniedException异常。该方法来自AbstractAccessDecisionManager的实现类，系统默认实现为AffirmativeBased。 new InterceptorStatusToken(SecurityContextHolder.getContext(), false, attributes, object);实现InterceptorStatusToken并返回，包括参数中的信息，如安全上下文、目标url所需权限、原始的访问请求。 之后则访问目标Controller，获取真正的请求内容。 afterInvocation当我们启用了@PreAuthorize()、@PostAuthorize()注解的时候则会AfterInvocationManger,进而有以下验证逻辑。 12345678910111213141516171819202122232425262728abstract class AbstractSecurityInterceptor &#123; protected Object afterInvocation(InterceptorStatusToken token, Object returnedObject) &#123; if (token == null) &#123; // public object return returnedObject; &#125; finallyInvocation(token); // continue to clean in this method for passivity if (afterInvocationManager != null) &#123; // Attempt after invocation handling try &#123; returnedObject = afterInvocationManager.decide(token.getSecurityContext() .getAuthentication(), token.getSecureObject(), token .getAttributes(), returnedObject); &#125; catch (AccessDeniedException accessDeniedException) &#123; AuthorizationFailureEvent event = new AuthorizationFailureEvent( token.getSecureObject(), token.getAttributes(), token .getSecurityContext().getAuthentication(), accessDeniedException); publishEvent(event); throw accessDeniedException; &#125; &#125; return returnedObject; &#125;&#125; 以下代码则是包含AfterInvocationManager具体的实现。 12345678910111213141516public class GlobalMethodSecurityConfiguration &#123; protected AfterInvocationManager afterInvocationManager() &#123; if (prePostEnabled()) &#123; AfterInvocationProviderManager invocationProviderManager = new AfterInvocationProviderManager(); ExpressionBasedPostInvocationAdvice postAdvice = new ExpressionBasedPostInvocationAdvice( getExpressionHandler()); PostInvocationAdviceProvider postInvocationAdviceProvider = new PostInvocationAdviceProvider( postAdvice); List&lt;AfterInvocationProvider&gt; afterInvocationProviders = new ArrayList&lt;&gt;(); afterInvocationProviders.add(postInvocationAdviceProvider); invocationProviderManager.setProviders(afterInvocationProviders); return invocationProviderManager; &#125; return null; &#125;&#125; 我们可以做些什么？ 实现FilterInvocationSecurityMetadataSource，用于启动时加载url所需的权限，这样就不用在configuration或者注解中将目标url权限‘写死’。可以参照本例所写的实现MyFilterInvocationSecurityMetadataSource。 重载AbstractAccessDecisionManager，根据业务需要重写，请求目标权限和Authentication中权限的验证过程.举个例子，Spring Security中默认的RBAC，即，权限认证都是根据角色判断，固定角色只能访问固定接口。现在我们需要ACL权限模型，用户A权限为1，用户B权限为5，用户C权限为9，接口a需要权限6，则用户C可以访问，而用户A、B不能访问，就是说权限大的可以访问权限小的接口，如果需要改变权限模型则重载该类即可。 总结授权过程主要有哪些？ 获取请求目标所需权限，从FilterInvocationSecurityMetadataSource接口的实现类获取。 对比安全上下文中Authentication中的权限是否匹配，在AbstractAccessDecisionManager的实现类中比较。 链接文章涉及到代码已传到gitee上，供大家参考： https://gitee.com/yangzijing/spring-security-demo Spring Security源码庞大且复杂，本人水平有限，文章难免有错漏、表述不清之处，请大家支出。欢迎交流，希望和大家共同进步。","categories":[],"tags":[{"name":"spring security","slug":"spring-security","permalink":"https://jevonyang.github.io/tags/spring-security/"}]},{"title":"Spring Security原理介绍、源码解析——认证过程","slug":"Spring Security原理介绍、源码解析——认证过程","date":"2019-03-15T07:13:58.000Z","updated":"2021-10-22T02:22:56.176Z","comments":true,"path":"2019/03/15/Spring Security原理介绍、源码解析——认证过程/","link":"","permalink":"https://jevonyang.github.io/2019/03/15/Spring%20Security%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D%E3%80%81%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E2%80%94%E2%80%94%E8%AE%A4%E8%AF%81%E8%BF%87%E7%A8%8B/","excerpt":"","text":"核心原理在前后端分离的架构中，权限认证主要包含两个主要的过程： 通过用户名密码换取一个令牌（Token），令牌具有不可修改性，以保证权限的安全。 用户在之后一段时间访问则不用再输入用户名密码，通过Token则可以访问被权限管理限制的接口。 再进一步说， 流程1，是通过用户名密码，从数据库中拿到用户的信息、权限等，并转换成安全框架（这里就是Spring Security）中可识别的身份信息（即Authentication），即视为登录成功，之后将必要的些信息转化为之后一段时间访问的凭证——Token。 流程2，则是将Token解析出来，转成安全框架中可识别身份信息，通过可识别的身份信息，框架再去判断该权限是否可以访问该端点。 可以看到在流程1&amp;2中，前半部分是相同的，都是将凭证（前者为用户名密码，后者为token）转为框架可识别的身份信息，这一步我们视为认证流程。后半部分则为，各自认证成功的操作逻辑。流程1生成token较为简单，流程2的后半部分则是安全框架（Spring Security）中权限管理的决策逻辑，即决定是否可以访问的逻辑，这一步我们视为授权流程。 下面将从认证和授权两部分来讲。 认证SecurityFilterChain 过滤器链Spring Security采用的是filterChain的设计方式，主要的功能大都由过滤器实现，在启动项目的时候，可以在日志中看到已有的过滤器，可在类似下面的日志里找到DefaultSecurityFilterChain，这里面则是SecurityFilterChain 12019-03-14 16:43:02.369 INFO 27251 --- [ restartedMain] o.s.s.web.DefaultSecurityFilterChain : Creating filter chain: org.springframework.security.web.util.matcher.AnyRequestMatcher@1, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@1d88a93d, org.springframework.security.web.context.SecurityContextPersistenceFilter@184d52d7, org.springframework.security.web.header.HeaderWriterFilter@29d86b1e, org.springframework.security.web.authentication.logout.LogoutFilter@2ce28138, org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter@320a4f73, com.yang.security.config.JwtAuthorizationTokenFilter@37e7a410, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@534e475b, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@39137df7, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@7c42403f, org.springframework.security.web.session.SessionManagementFilter@1fa2ad2b, org.springframework.security.web.access.ExceptionTranslationFilter@65869e97, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@163d3c44] 把各个过滤器抽取出来，我们可以看到是这样，这也是过滤器链的先后顺序。 12345678910111. WebAsyncManagerIntegrationFilter2. SecurityContextPersistenceFilter3. HeaderWriterFilter4. LogoutFilter5. **UsernamePasswordAuthenticationFilter**6. **JwtAuthorizationTokenFilter**7. RequestCacheAwareFilter8. SecurityContextHolderAwareRequestFilter9. SessionManagementFilter10. ExceptionTranslationFilter11. FilterSecurityInterceptor 这里主要讲一下UsernamePasswordAuthenticationFilter及相关的代码，顺带的说一下，我们自己实现JwtAuthenticationFilter及周边。 示例： 官方的Filter——UsernamePasswordAuthenticationFilter过程UsernamePasswordAuthenticationFilterUsernamePasswordAuthenticationFilter，顾名思义，是用来处理用户名密码登录的过滤器。所有的Filter核心方法都是doFilter，该过滤器的doFilter在其父抽象类中，过滤器只需实现attemptAuthentication方法即可。 源码摘录如下（并不是完整的源码，拣选重要部分阐述逻辑）： 12345678910111213141516public class UsernamePasswordAuthenticationFilter extends AbstractAuthenticationProcessingFilter &#123; public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException &#123; String username = obtainUsername(request); String password = obtainPassword(request); // 根据用户名密码构造AuthenticationToken UsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken( username, password); // 将AuthenticationToken放入AuthenticationProvider进行认证 return this.getAuthenticationManager().authenticate(authRequest); &#125;&#125; AuthenticationManagerAuthenticationManager中维护着一个List&lt;AuthenticationProvider&gt;；首先通过AuthenticationProvider的supports方法检测是否支持该类型的AuthenticationToken；如果支持，则使用authenticate认证，认证通过则将AuthenticationToken转换成经认证的Authentication。 12345678910111213141516171819202122232425262728293031323334353637public class ProviderManager implements AuthenticationManager, MessageSourceAware, InitializingBean &#123; private List&lt;AuthenticationProvider&gt; providers = Collections.emptyList(); private AuthenticationManager parent; private boolean eraseCredentialsAfterAuthentication = true; // 遍历Providers public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; for (AuthenticationProvider provider : getProviders()) &#123; // 如果Authentication不符合，跳过后边步骤，继续循环 if (!provider.supports(toTest)) &#123; continue; &#125; // 如果Authentication符合，则使用该Provider进行authenticate操作 result = provider.authenticate(authentication); if (result != null) &#123; copyDetails(authentication, result); break; &#125; &#125; if (result != null) &#123; if (eraseCredentialsAfterAuthentication &amp;&amp; (result instanceof CredentialsContainer)) &#123; ((CredentialsContainer) result).eraseCredentials(); &#125; return result; &#125; &#125; &#125; DaoAuthenticationProvider接下来，说如何将AuthenticationToken认证。下面是DaoAuthenticationProvider的父抽象类，父类中核心方法就是authenticate方法，而子类则只用实现retrieveUser方法，该方法调用UserDetailsService的loadUserByUsername。对于我们用户而言，所要做的就是实现UserDetailsService，重写其中的方法，通过loadUserByUsername从数据库中拿到用户名和密码，至于后面的验证，事实上都是由AbstractUserDetailsAuthenticationProvider已经做好了。 12345678910111213141516171819202122232425262728public abstract class AbstractUserDetailsAuthenticationProvider implements AuthenticationProvider, InitializingBean, MessageSourceAware &#123; public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; String username = (authentication.getPrincipal() == null) ? &quot;NONE_PROVIDED&quot;: authentication.getName(); // DaoAuthenticationProvider中重载retrieveUser方法，而该方法中的核心方法就是UserDetailsService的loadUserByUsername user = retrieveUser(username, (UsernamePasswordAuthenticationToken) authentication); // preCheck preAuthenticationChecks.check(user); additionalAuthenticationChecks(user, (UsernamePasswordAuthenticationToken) authentication); // postCheck postAuthenticationChecks.check(user); // 检查成功没有问题，则创建Authentication示例 return createSuccessAuthentication(principalToReturn, authentication, user); &#125; public boolean supports(Class&lt;?&gt; authentication) &#123; return (UsernamePasswordAuthenticationToken.class .isAssignableFrom(authentication)); &#125;&#125; 总结一下 UsernamePasswordAuthenticationFilter.doFilter获取用户名密码,生成UsernamePasswordAuthenticationToken； 将UsernamePasswordAuthenticationToken交给DaoAuthenticationProvider验证； DaoAuthenticationProvider通过UserDetailsService.loadUserByUsername中获取用户名、密码、权限以及其他信息，并进行比对；比对成功，则生成Authentication； UsernamePasswordAuthenticationFilter将Authentication放入SecurityContextHolder，认证成功； 齐活！ 实践：编写自己的Filter——JwtAuthenticationFilter流程2的主要功能，解析Token，转换成Spring Security内部可识别的身份信息Authentication，并放入上下文中，这一步则是通过JwtAuthenticationFilter来完成，其原理与UsernamePasswordAuthenticationFilter并无二致，我们简单来看一下，当做一个小小的实践练习。 JwtAuthorizationTokenFilter首先编写JwtAuthorizationTokenFilter。我们直接扩展了AbstractAuthenticationProcessingFilter这个抽象类,因为想使用其requiresAuthentication方法判断访问端点是否需要经过该过滤器；于此同时我们需要实现一个RequestMatch匹配访问信息，具体实现按下不表，可以参考代码中SkipUrlMatcher实现自己的业务逻辑。 接下来，我们将获取的access_token解析，转化成UserDetails，代码中Step1中的User即为其具体实现。我们知道，jwt事实上是加密的，只有通过我们自己的秘钥解析才能验证成功，获取内部信息。事实上在这一步骤，我们已经验证了信息的真实性、可用性（Step1），就直接生成JwtAuthenticationToken（Step2），这里的authentication已经经过验证，放入AuthenticationManager.authenticate过程得到框架可识别的认证信息Authentication。将已认证身份信息放入上下文，认证过程完成。 123456789101112131415161718192021222324252627282930313233343536public class JwtAuthorizationTokenFilter extends AbstractAuthenticationProcessingFilter &#123; public JwtAuthorizationTokenFilter(RequestMatcher matcher) &#123; super(matcher); &#125; @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; HttpServletRequest httpServletRequest = (HttpServletRequest) request; HttpServletResponse httpServletResponse = (HttpServletResponse) response; // Step0. 首先判断访问的端点是否需要经过该过滤器 if (!requiresAuthentication(httpServletRequest, httpServletResponse)) &#123; filterChain.doFilter(httpServletRequest, httpServletResponse); return; &#125; String token = httpServletRequest.getHeader(&quot;Authorization&quot;); // Step1. 将token转换成UserDetails(这里的User是自己写的UserDetail的实现) User user = JwtUtil.accessToken2User(token.substring(7)); // Step2. 将UserDetails转换成Authentication，这里的JwtAuthenticationToken即为Authentication的实现， // 一般而言，将UserDetails放入Authentication的principle中,之后如果需要可通过Authentication.getPrinciple的方法把UserDetails取出来 JwtAuthenticationToken authenticationToken = new JwtAuthenticationToken(user, token, user.getAuthorities()); // Step3. 这一步将AuthenticationToken交由AuthenticationProvider处理，转换成Authentication final Authentication authentication = getAuthenticationManager().authenticate(authenticationToken); // Step4. 将得到的Authentication实例放入Holder，则认证完成 SecurityContextHolder.getContext().setAuthentication(authentication); // Step5. 进入之后的过滤器处理 filterChain.doFilter(httpServletRequest, httpServletResponse); &#125;&#125; JwtAuthenticationProvider再来看一下自定义的JwtAuthenticationProvider。通过前面的一小节我们知道，AuthenticationManager.authenticate过程实际上是通过具体的AuthenticationProvider完成，我们前面得到了一个JwtAuthenticationToken，我们就专门实现一个处理该实例的AuthenticationProvider。在该实现方法里，authenticate过程我直接将传入的authentication（实例为jwtAuthenticationToken）直接返回，是因为Jwt解析过程需要对JWT进行解密、验证，所以我们传入的JwtAuthenticationToken已经是验证过的，故在这里没做过多的处理。 123456789101112public class JwtAuthenticationProvider implements AuthenticationProvider &#123; @Override public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; return authentication; &#125; @Override public boolean supports(Class&lt;?&gt; authentication) &#123; return (JwtAuthenticationToken.class.isAssignableFrom(authentication)); &#125;&#125; 总结一下我们干了什么 实现一个自定义AuthorizationTokenFilter，实现doFilter方法，该方法则是认证的整个过程。 获取请求信息（这一节获取的信息是JWT，上一节获取的是用户名密码），将这些信息生成一个AuthenticationToken（这一节生成的JwtAuthenticationToken，上一节是UsernamePasswordToken） 将AuthenticationToken交给AuthenticationProvider验证，在supports方法中验证是否支持该类型的AuthenticationToken，在authenticate方法中完成验证的过程。 将认证后的Authentication实例放入安全上下文SecurityContextHolder，认证过程全部完成。 文章涉及到代码已传到gitee上，供大家参考： https://gitee.com/yangzijing/spring-security-demo Spring Security源码庞大且复杂，本人水平有限，文章难免有错漏、表述不清之处，请大家支出。欢迎交流，希望和大家共同进步。","categories":[],"tags":[{"name":"spring security","slug":"spring-security","permalink":"https://jevonyang.github.io/tags/spring-security/"}]},{"title":"SpringCloud实践分享-日志收集Kafka-ELK","slug":"SpringCloud实践分享-日志收集Kafka-ELK","date":"2018-06-11T01:53:58.000Z","updated":"2021-10-22T02:22:56.176Z","comments":true,"path":"2018/06/11/SpringCloud实践分享-日志收集Kafka-ELK/","link":"","permalink":"https://jevonyang.github.io/2018/06/11/SpringCloud%E5%AE%9E%E8%B7%B5%E5%88%86%E4%BA%AB-%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86Kafka-ELK/","excerpt":"","text":"微服务应用在容器化后，日志的查询就会变成困难的问题，虽说有portainer这类的容器管理工具，能够方便的查询每个容器中的日志，但容器到达一定数量后，尤其是应用有多个实例时候，查询就成了头疼的问题。所以我们采用了Kafka-Logstash-Elasticsearch-Kibana的方案来处理日志。 首先说说我的日志收集思路： 应用将日志传入kafka集群。在集群建立相应topic，并传入日志。 logstash在kafka上消费（读取）日志内容，写入elasticsearch。 kibana读elasticsearch，做对应的展示。 这样的好处，1）几乎不用做特别大的修改，只需做一定的配置工作即可完成日志收集；2）日志内容输入kafka几乎没有什么瓶颈，另外kafka的扩展性能很好，也很简单；3）收集的日志几乎是实时的；4）整体的扩展性很好，很容易消除瓶颈，例如elasticsearch分片、扩展都很容易。 应用侧配置在应用中，我们只需配置log4j的相应配置，将其日志输出到kafka即可。以下为配置示例，配置中包含将日志输入出命令行和kafka部分中。注意，在输出到kafka中，需要有一个appender类kafka.producer.KafkaLog4jAppender一般是没有的，则我在本地自己写上该类（KafkaLog4jAppender.java），并加入相应的文件路径。 123456789101112131415161718log4j.rootLogger=INFO,console,kafka# 输出到kafkalog4j.appender.kafka=com.yang.config.KafkaLog4jAppender #kafka.producer.KafkaLog4jAppenderlog4j.appender.kafka.topic=api-adminlog4j.appender.kafka.brokerList=192.0.0.2:9092,192.0.0.3:9092,192.0.0.4:9092 # 这里填写kafka的iplog4j.appender.kafka.compressionType=nonelog4j.appender.kafka.syncSend=truelog4j.appender.kafka.layout=org.apache.log4j.PatternLayoutlog4j.appender.kafka.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss&#125; %-5p %c&#123;1&#125;:%L %% - %m%n# 输出到Consolelog4j.appender.console=org.apache.log4j.ConsoleAppenderlog4j.appender.console.target=System.errlog4j.appender.console.layout=org.apache.log4j.PatternLayoutlog4j.appender.console.layout.ConversionPattern=%d (%t) [%p - %l] %m%n KafkaLog4jAppender.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203public class KafkaLog4jAppender extends AppenderSkeleton &#123; private static final String BOOTSTRAP_SERVERS_CONFIG = ProducerConfig.BOOTSTRAP_SERVERS_CONFIG; private static final String COMPRESSION_TYPE_CONFIG = ProducerConfig.COMPRESSION_TYPE_CONFIG; private static final String ACKS_CONFIG = ProducerConfig.ACKS_CONFIG; private static final String RETRIES_CONFIG = ProducerConfig.RETRIES_CONFIG; private static final String KEY_SERIALIZER_CLASS_CONFIG = ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG; private static final String VALUE_SERIALIZER_CLASS_CONFIG = ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG; private static final String SECURITY_PROTOCOL = CommonClientConfigs.SECURITY_PROTOCOL_CONFIG; private static final String SSL_TRUSTSTORE_LOCATION = SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG; private static final String SSL_TRUSTSTORE_PASSWORD = SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG; private static final String SSL_KEYSTORE_TYPE = SslConfigs.SSL_KEYSTORE_TYPE_CONFIG; private static final String SSL_KEYSTORE_LOCATION = SslConfigs.SSL_KEYSTORE_LOCATION_CONFIG; private static final String SSL_KEYSTORE_PASSWORD = SslConfigs.SSL_KEYSTORE_PASSWORD_CONFIG; private String brokerList = null; private String topic = null; private String compressionType = null; private String securityProtocol = null; private String sslTruststoreLocation = null; private String sslTruststorePassword = null; private String sslKeystoreType = null; private String sslKeystoreLocation = null; private String sslKeystorePassword = null; private int retries = 0; private int requiredNumAcks = Integer.MAX_VALUE; private boolean syncSend = false; private Producer&lt;byte[], byte[]&gt; producer = null; public Producer&lt;byte[], byte[]&gt; getProducer() &#123; return producer; &#125; public String getBrokerList() &#123; return brokerList; &#125; public void setBrokerList(String brokerList) &#123; this.brokerList = brokerList; &#125; public int getRequiredNumAcks() &#123; return requiredNumAcks; &#125; public void setRequiredNumAcks(int requiredNumAcks) &#123; this.requiredNumAcks = requiredNumAcks; &#125; public int getRetries() &#123; return retries; &#125; public void setRetries(int retries) &#123; this.retries = retries; &#125; public String getCompressionType() &#123; return compressionType; &#125; public void setCompressionType(String compressionType) &#123; this.compressionType = compressionType; &#125; public String getTopic() &#123; return topic; &#125; public void setTopic(String topic) &#123; this.topic = topic; &#125; public boolean getSyncSend() &#123; return syncSend; &#125; public void setSyncSend(boolean syncSend) &#123; this.syncSend = syncSend; &#125; public String getSslTruststorePassword() &#123; return sslTruststorePassword; &#125; public String getSslTruststoreLocation() &#123; return sslTruststoreLocation; &#125; public String getSecurityProtocol() &#123; return securityProtocol; &#125; public void setSecurityProtocol(String securityProtocol) &#123; this.securityProtocol = securityProtocol; &#125; public void setSslTruststoreLocation(String sslTruststoreLocation) &#123; this.sslTruststoreLocation = sslTruststoreLocation; &#125; public void setSslTruststorePassword(String sslTruststorePassword) &#123; this.sslTruststorePassword = sslTruststorePassword; &#125; public void setSslKeystorePassword(String sslKeystorePassword) &#123; this.sslKeystorePassword = sslKeystorePassword; &#125; public void setSslKeystoreType(String sslKeystoreType) &#123; this.sslKeystoreType = sslKeystoreType; &#125; public void setSslKeystoreLocation(String sslKeystoreLocation) &#123; this.sslKeystoreLocation = sslKeystoreLocation; &#125; public String getSslKeystoreLocation() &#123; return sslKeystoreLocation; &#125; public String getSslKeystoreType() &#123; return sslKeystoreType; &#125; public String getSslKeystorePassword() &#123; return sslKeystorePassword; &#125; @Override public void activateOptions() &#123; // check for config parameter validity Properties props = new Properties(); if (brokerList != null) props.put(BOOTSTRAP_SERVERS_CONFIG, brokerList); if (props.isEmpty()) throw new ConfigException(&quot;The bootstrap servers property should be specified&quot;); if (topic == null) throw new ConfigException(&quot;Topic must be specified by the Kafka log4j appender&quot;); if (compressionType != null) props.put(COMPRESSION_TYPE_CONFIG, compressionType); if (requiredNumAcks != Integer.MAX_VALUE) props.put(ACKS_CONFIG, Integer.toString(requiredNumAcks)); if (retries &gt; 0) props.put(RETRIES_CONFIG, retries); if (securityProtocol != null &amp;&amp; sslTruststoreLocation != null &amp;&amp; sslTruststorePassword != null) &#123; props.put(SECURITY_PROTOCOL, securityProtocol); props.put(SSL_TRUSTSTORE_LOCATION, sslTruststoreLocation); props.put(SSL_TRUSTSTORE_PASSWORD, sslTruststorePassword); if (sslKeystoreType != null &amp;&amp; sslKeystoreLocation != null &amp;&amp; sslKeystorePassword != null) &#123; props.put(SSL_KEYSTORE_TYPE, sslKeystoreType); props.put(SSL_KEYSTORE_LOCATION, sslKeystoreLocation); props.put(SSL_KEYSTORE_PASSWORD, sslKeystorePassword); &#125; &#125; props.put(KEY_SERIALIZER_CLASS_CONFIG, &quot;org.apache.kafka.common.serialization.ByteArraySerializer&quot;); props.put(VALUE_SERIALIZER_CLASS_CONFIG, &quot;org.apache.kafka.common.serialization.ByteArraySerializer&quot;); this.producer = getKafkaProducer(props); LogLog.debug(&quot;Kafka producer connected to &quot; + brokerList); LogLog.debug(&quot;Logging for topic: &quot; + topic); &#125; protected Producer&lt;byte[], byte[]&gt; getKafkaProducer(Properties props) &#123; return new KafkaProducer&lt;byte[], byte[]&gt;(props); &#125; @Override protected void append(LoggingEvent event) &#123; String message = subAppend(event); LogLog.debug(&quot;[&quot; + new Date(event.getTimeStamp()) + &quot;]&quot; + message); Future&lt;RecordMetadata&gt; response = producer.send(new ProducerRecord&lt;byte[], byte[]&gt;(topic, message.getBytes())); if (syncSend) &#123; try &#123; response.get(); &#125; catch (InterruptedException ex) &#123; throw new RuntimeException(ex); &#125; catch (ExecutionException ex) &#123; throw new RuntimeException(ex); &#125; &#125; &#125; private String subAppend(LoggingEvent event) &#123; return (this.layout == null) ? event.getRenderedMessage() : this.layout.format(event); &#125; public void close() &#123; if (!this.closed) &#123; this.closed = true; producer.close(); &#125; &#125; public boolean requiresLayout() &#123; return true; &#125;&#125; logstash配置logstash可能会有快速启动实例的需求，我们就采用docker部署，能够快速启动、扩展等功能。 镜像就直接logstash官方镜像logstash docker镜像，我们选择了一种最简单启动方式做演示，具体还有多种docker部署方法，可以参考以上链接。 docker启动命令，input输入中，指定kafka集群地址和对应topic；输出，则是elasticsearch集群地址、索引，以及elastisearch配置参数。 1234567891011#启动命令docker run -it -d logstash -e &#x27;input &#123; kafka &#123; bootstrap_servers =&gt; &quot;kafkaIp1:9092,kafkaIp2:9092&quot; topics =&gt; [&quot;api-admin&quot;] &#125; &#125; output &#123; elasticsearch &#123; hosts =&gt; [&quot;elasticsearch1:9200&quot;,&quot;elasticsearch2:9200&quot;,&quot;elasticsearch3:9200&quot;] index =&gt; &quot;api-admin-%&#123;+YYYY.MM.dd&#125;&quot; flush_size =&gt; 20000 idle_flush_time =&gt; 10 template_overwrite =&gt; true &#125; &#125;&#x27; 在marathon中启动在Command选项中加入参数logstash -e &#39;input &#123;&#125; output &#123;&#125;&#39;即可。另外说一句， 如果在容器编排系统（mesos/marathon、kubernetes）中，可能会有健康检查要求，其端口为9600。","categories":[],"tags":[{"name":"spring cloud","slug":"spring-cloud","permalink":"https://jevonyang.github.io/tags/spring-cloud/"}]},{"title":"SpringCloud实践分享-Config配置中心","slug":"SpringCloud实践分享-Config配置中心","date":"2018-06-07T06:17:58.000Z","updated":"2021-10-22T02:22:56.176Z","comments":true,"path":"2018/06/07/SpringCloud实践分享-Config配置中心/","link":"","permalink":"https://jevonyang.github.io/2018/06/07/SpringCloud%E5%AE%9E%E8%B7%B5%E5%88%86%E4%BA%AB-Config%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/","excerpt":"","text":"简介在服务中经常会遇到一些易变的参数，例如数据库地址、超时时间等等。这些参数与代码关系耦合度低，但是每改一次就去修改代码中的参数，再去编译部署显得很蠢，于是就有了配置中心得个实现。目前用的比较多的配置中心有SpringCloudConfig和携程的Apollo。SpringCloudConfig的好处是和SpringCloud绑定，全家桶（有好处有坏处，你懂的），部署简单；而Apollo部署比较麻烦，它首先要把部署地址写死在apollo-client中编译出来，然后在配置项目中引用apollo-client……（既然是配置中心，为什么配置中心本身不能做到代码和参数的解耦？！）当然，这都是我一些私货，事实上apollo功能十分强大，权限功能完整，并且支持多语言，大家都知道携程的技术栈主要是.net。两种各有长短，有兴趣的同学可以去github上看看，文档说明十分详细。书归正传，接下来主要讲Spring Cloud Config。 启动ConfigConfig的配置同样简单:加入依赖spring-cloud-config-server，入口类加入注解@EnableConfigServer和@EnableDiscoveryClient，前一个注解是使能Config注册中心，后一个则是注册到Eureka上，让其他服务找到该服务。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt; 12345678@EnableDiscoveryClient@EnableConfigServer@SpringBootApplicationpublic class ConfigApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigApplication.class, args); &#125;&#125; Config Server配置首先说注册中心Eureka相关内容，服务注册地址eureka.client.serviceUrl.defaultZone以及自己是谁spring.application.name即可。我在这里加上prefer-ip-address的配置，后面会相信说明。 123456789spring: application: name: config-servereureka: instance: prefer-ip-address: true client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 然后是就是配置中心相关内容。配置中心一般采用git或svn才作为配置存储端，官方文档上还有以jdbc数据库来存储的，本文以git来说明。其中spring.cloud.config.server.uri是配置文件存放的git地址，为了更直观演示，我在gitee上配置相应的内容。而search-paths则是在该库下的搜索路径，我们这里配置成了&#39;&#123;application&#125;&#39;代表不同服务会去git项目下找与项目名（spring.application.name）对应的文件。其规则为&#123;application&#125;-&#123;profile&#125;.yml 例如，服务A中spring.application.name: fuwu1,则服务A在启动的时，配置中心则会找git.uri下的fuwu1.yml文件交给服务A作为配置。服务A启动时，带有-Dspring.profiles.active=master参数时,则会配置中心则会找git.uri下的fuwu1-master.yml文件交给服务A作为配置。 配置同样需要有权限管理，而配置中心的权限逻辑和git相同（如果你使用git作为存储后端）。我们可以配置username和password，如果需要有更高的要求，还可以和git一样，配置公钥私钥。在git上放上公钥，在private-key这里直接填写私钥内容，你甚至可以代码上去掉权限信息，而在部署的服务器中配上私钥。总之，git是怎么配它就是怎么配置。（git相关内容点击这里） 还有一种配置路径的逻辑大概是这样：uri: git@your-git-address:your-config-repo/&#123;application&#125;.git，不同的项目配置放在不同的仓库，这样可以配置不同仓库的权限。如果是这样配置，仓库里的文件命规则是application-&#123;profile&#125;.yml。 1234567891011spring: cloud: config: server: git: uri: git@gitee.com:yangzijing/config.git search-paths: &#x27;&#123;application&#125;&#x27; #uri: git@your-git-address:your-config-repo/&#123;application&#125;.git #private-key: #username: yourusername #password: yourpassword Config客户端配置客户端配置同样也是两类，eureka的配置和config的配置，要注意这些配置要写在bootstrap.yml中。简单来讲bootstrap和application的区别，bootstrap.yml中的配置先启动，application.yml中的配置后启动，而需要动态配置的配置项则写在application.yml中。 Eureka相关的配置不再赘述，主要关心一下config的配置。配置可以有两种，1）指定config的ip，直接在spring.cloud.config.uri配上地址即可。2）通过Eureka找到Config的地址,配置spring.cloud.config.discovery.enabled=true和discovery.service-id(这里的service-id和config项目的spring.application.name名字一致，其默认值是configserver)。 123456789spring: application: name: api-admin cloud: config: #uri: http://ip:port discovery: enabled: true service-id: config-server 在api-admin项目中，增加了一个from配置，在application.yml可写可不写，如果写，还可以添加默认值from: $&#123;from:hello&#125;;如果不写，也可以，同样也可以在java文件中直接引用,例如： 12@Value(&quot;$&#123;from&#125;&quot;)private String from; 但是要注意的是，使用了配置中心功能后，如果占位符（${xxx}）没有被正确替换，整个程序是会报错了，不管你用了没用默认值，这个是不科学的。 利用WebHook自动刷新在引用了配置的类上添加@RefreshScope注解，即可实现自动刷新，还有一点，需要在git中的webhook（例如GitHub，GitLab，Gitee）添加上http://config-ip:port/bus/refresh即可。 流程大致为： git仓库更新 -&gt; 触发webhook-&gt; 触发config的刷新端点-&gt; config通知应用 -&gt; 应用刷新配置内容。 遇到的一个prefer-ip-address问题在调试过程中发现一个问题，如果在config服务端prefer-ip-address没有打开，客户端则会找不到config服务端。在网上找了一下关于该配置的解释，希望对大家有用prefer-ip-address机制解释 config的大致内容就说完了，可能还差配置内容加密，稍微有些繁杂，有机会再补充，急需可以查一下官方文档，或者别的中文博客","categories":[],"tags":[{"name":"spring cloud","slug":"spring-cloud","permalink":"https://jevonyang.github.io/tags/spring-cloud/"}]},{"title":"SpringCloud实践分享-Eureka注册中心","slug":"SpringCloud实践分享-Eureka注册中心","date":"2018-06-07T03:21:58.000Z","updated":"2021-10-22T02:22:56.176Z","comments":true,"path":"2018/06/07/SpringCloud实践分享-Eureka注册中心/","link":"","permalink":"https://jevonyang.github.io/2018/06/07/SpringCloud%E5%AE%9E%E8%B7%B5%E5%88%86%E4%BA%AB-Eureka%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83/","excerpt":"","text":"随着业务需求增加，众多企业面临代码耦合严重、效率低下的问题。在Netflix开源了一套自己的微服务架构后，Spring随即也基于此推出SpringCloud。目前来说，SpringCloud的门槛相对较低，在了解大致SpringCloud后即可上手，更多的是配置，或者是套路上的东西。当然我这么说只是对于希望快速上手的同学而言，源码博大精深，有兴趣可以多多研究。自己做微服务的也做了半年了，现在写一个demo，总结一下springcloud的基本用法，让我们的微服务的小车先开起来。 spring-cloud-microservice代码 项目构成项目采用module的形式，一个项目下分多个module，导入项目比较方便。 []Eureka注册中心 []Config配置中心 []Oauth2认证中心 []Zuul网关 []api-admin服务 注册中心EurekaEureka作为服务的注册中心，服务间的互相调用都是通过Eureka来完成，所有的服务都将自己注册到eureka中。当A服务希望调用B服务时，A只需使用B的instanceId，而不是ip，即可完成调用。在分布式应用中，服务随机部署在各个服务器中，根据ip去调用服务极其低效，你再写代码。当服务启动多个实例时候，一般使用ribbon和feign，则会自动负载均衡，无需干预。 想启动一个Eureka服务注册中心，配置上也十分简单。首先在pom.xml中加入spring-cloud-starter-eureka-server依赖，再在入口类中加入注解@EnableEurekaServer即可。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; 1234567@EnableEurekaServer@SpringBootApplicationpublic class EurekaApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaApplication.class, args); &#125;&#125; 如果Eureka只希望standalone模式（只启动一个实例），事实上在配置文件application.yml无需配置内容，配置上基本信息以及端口即可。如果希望启动HighAvailability模式(即启动多个实例),则可以参考一下配置。 在部署的时候，使用编译后同一个jar包，在启动后输入不同参数。例如使用命令java -jar -Dspring.profiles.active=master your_jar_name.jar，则启动配置spring.profiles为配置master下的内容。而最上面一块的内容为公共配置，启动master配置时，实际的配置时公共配置+master配置；如果有些配置两边都有，则master配置会覆盖公共配置内容。 123456789101112131415161718192021222324252627282930313233343536373839404142434445#公共配置server: port: 8080spring: application: name: eureka-servereureka: instance: lease-renewal-interval-in-seconds: 5 lease-expiration-duration-in-seconds: 5 prefer-ip-address: true client: register-with-eureka: true fetch-registry: true---# 配置masterspring: profiles: mastereureka: instance: hostname: master client: service-url: defaultZone: http://master:8080/eureka/,http://backup1:8080/eureka/,http://backup2:8080/eureka/---# 配置backup1spring: profiles: backup1eureka: client: service-url: defaultZone: http://master:8080/eureka/,http://backup1:8080/eureka/,http://backup2:8080/eureka/---# 配置backup2spring: profiles: backup2eureka: client: service-url: defaultZone: http://master:8080/eureka/,http://backup1:8080/eureka/,http://backup2:8080/eureka/ 下面来说一个几个重点配置 eureka.client.registry-fetch-interval-seconds表示服务间隔多久去Eureka中获取注册信息，默认为30s。 eureka.instance.lease-renewal-interval-in-seconds表示服务给Eureka发送心跳间隔，默认为30s。如果该instance实现了HealthCheckCallback，并决定让自己unavailable的话，则该instance也不会接收到流量。 eureka.instance.lease-expiration-duration-in-seconds表示Eureka上次收到服务的心跳后，等待下一次心跳的时间，如果超时则移除实例，默认为90s。 eureka.server.enable-self-preservation表示是否开启自我保护模式，默认为true。默认情况下，如果Eureka Server在一定时间内没有接收到某个微服务实例的心跳，Eureka Server将会注销该实例（默认90秒）。但是当网络分区故障发生时，微服务与Eureka Server之间无法正常通信，以上行为可能变得非常危险了——因为微服务本身其实是健康的，此时本不应该注销这个微服务。Eureka通过“自我保护模式”来解决这个问题——当Eureka Server节点在短时间内丢失过多客户端时（可能发生了网络分区故障），那么这个节点就会进入自我保护模式。一旦进入该模式，Eureka Server就会保护服务注册表中的信息，不再删除服务注册表中的数据（也就是不会注销任何微服务）。当网络故障恢复后，该Eureka Server节点会自动退出自我保护模式。综上，自我保护模式是一种应对网络异常的安全保护措施。它的架构哲学是宁可同时保留所有微服务（健康的微服务和不健康的微服务都会保留），也不盲目注销任何健康的微服务。使用自我保护模式，可以让Eureka集群更加的健壮、稳定。 eureka.server.eviction-interval-timer-in-ms表示Eureka清理无效节点的时间间隔，默认为60,000ms。 eureka.client.register-with-eureka表示是否将Eureka注册到自身，多实例中一边选择true。 eureka.client.fetch-registry表示是否拉去注册的服务。假设，服务A只注册到master节点的Eureka，但是开启该选项，所有的Eureka节点都会注册该服务。 eureka.client.defaultZone表示希望注册到Eureka的地址，格式为http://ip:port/eureka/,如果部署环境有dns，也可以将ip换成域名，如果有是ha模式，配置多个地址用逗号隔开。 以上为Eureka配置相对重要的配置。","categories":[],"tags":[{"name":"spring cloud","slug":"spring-cloud","permalink":"https://jevonyang.github.io/tags/spring-cloud/"}]},{"title":"DevOps：GitLab+Jenkins+Docker实践分享","slug":"DevOps：GitLab+Jenkins+Docker实践分享","date":"2017-08-08T07:37:58.000Z","updated":"2021-10-22T02:22:56.176Z","comments":true,"path":"2017/08/08/DevOps：GitLab+Jenkins+Docker实践分享/","link":"","permalink":"https://jevonyang.github.io/2017/08/08/DevOps%EF%BC%9AGitLab+Jenkins+Docker%E5%AE%9E%E8%B7%B5%E5%88%86%E4%BA%AB/","excerpt":"","text":"相信很多小团队仍然在使用SVN+手动发版的这样的方法，当代码量不断膨胀、开发人员不断上升，在管理上会愈发吃力。最近，领导说，小杨啊，我们要提升开发效率。于是，选择了Gitlab+Jenkins的主流工具，过程中遇到很多坑，希望和大家分享。 GitLab GitLab简单的说就是自建版的Github，可以安装到自己的服务器上，主要功能代码管理、权限管理、代码可视化、需求管理。 Server: Ubuntu 14.04 GitLab:10.0.1 安装配置 GitLab安装依赖包 1sudo apt-get install curl openssh-server ca-certificates postfix 首先信任 GitLab 的 GPG 公钥: 1curl https://packages.gitlab.com/gpg.key 2&gt; /dev/null | sudo apt-key add - &amp;&gt;/dev/null 修改或新建/etc/apt/sources.list.d/gitlab-ce.list加入清华的gitlab源，因为官方源实在是太慢了 1deb https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/ubuntu trusty main 安装 gitlab-ce: 12sudo apt-get updatesudo apt-get install gitlab-ce 安装完成后，修改/etc/gitlab/gitlab.rb文件（有的文章说改别的地方，不推荐，Ubuntu 14.04改这里就行），将gitlab.example.com换为当前服务器的ip，例如192.168.1.1。 1external_url &#x27;http://gitlab.example.com&#x27; 接着就重新配置gitlab，然后重启GitLab服务： 12sudo gitlab-ctl reconfigure#重新配置sudo gitlab-ctl restart#重新启动gitlab服务 服务重启完成后，在浏览器中输入服务器ip，不用加端口号，即可进入GitLab的界面，GitLab和Github功能大致一致。至于不会git操作的用户，请移步Git简明教程 报错处理 在浏览器输入地址后，出现502：重新配置然后重启，一般来说gitlab启动需要一段时间，稍等即可。 在浏览器输入地址后，出现nginx、apache2或者别的：关闭相关服务，后重启gitlab。 DockerDocker: 17.0 Docker的安装方法便不再赘述，官方教程很详细，简单明了。 Docker官方安装教程：Ubuntu CentOS Docker-Compose 顺便再推荐Docker官方教程，以及Docker官方镜像仓库几乎所有工具的镜像在这里都可以找到。不出几年，我们将抛开所有繁杂的安装过程，拥抱docker镜像。 重点说一下的几个配置，在网上有很多教程、回答，在17版本中都已经失效。总体来说，目前版本（17.0.x）的docker的设置都配置化，不用再在docker的执行脚本中修改。 访问远程Docker被访问服务器中修改/etc/default/docker文件添加：0.0.0.0代表任何ip都可以访问，当然需要限制访问ip可以在这里设置。 1DOCKER_OPTS=&quot;-H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock&quot; 私有仓库私有仓库是很有用的功能，简单几条命令即可创建私有仓库，同时，将自己的镜像上传到私有仓库，既保障的镜像安全，也为镜像备份。 12docker pull registrydocker run -d -p 5000:5000 registry 私有仓库开启后，push或者pull的时候会报链接错误。此时需要修改/etc/docker/daemon.json文件即可，如下： 1234&#123; &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;], &quot;insecure-registries&quot;:[&quot;x.x.x.x:5000&quot;]&#125; 在Stackoverflow上很多回答说修改/etc/init.d/docker或 /etc/sysconfig/docker抑或其他，在当前版本都是行不通。 Docker代理某些地方的服务器不能连外网，此时需要代理。创建/etc/systemd/system/docker.service.d/http-proxy.conf文件，添加以下内容： 12[Service]Environment=&quot;HTTP_PROXY=http://proxy.example.com:80/&quot; 若果需要https代理创建https-proxy.conf文件并做相应修改即可。接着重新载入Docker配置，重启服务，代理生效。 1systemctl daemon-reload JenkinsServer: CentOS 7.2 Jenkins:2.7.9 安装 首先添加yum源，然后使用yum安装，Jenkins本质上是一个war包，一定要注意在此之前需要安装Java。123sudo wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/RedHat/jenkins.reposudo rpm --import https://jenkins-ci.org/redhat/jenkins-ci.org.keysudo yum install jenkins 接下来配置/etc/sysconfig/jenkins文件，最重要的两条，一条是当前机器Java的路径；以及Jenkins的端口号，默认为8080，如果已被占用可以更换。12JENKINS_JAVA_CMD=&quot;/usr/local/java/jdk1.8/bin/java&quot;JENKINS_PORT=&quot;8080&quot; Jenkins服务重启12sudo service jenkins start/stop/restartsudo chkconfig jenkins on 之后便可以在浏览器输入服务器ip:8080，看到Jenkins的页面。按照提示/var/lib/jenkins/secrets/initalAdminPassword文件中找到管理员密码，然后一路next即可，进入Jenkins界面。 配置 系统管理-&gt;Global Tool Configuration分别设置JDK、Git、Maven、Docker，其中name都是随便填的，路径填入相应软件的路径，值得注意的是有的只需要精确到所在文件，有的则需要精确到执行文件。当然，如果填的不对，会有黄字或红字提示。 系统管理-&gt;系统设置 中需要配置Maven项目配置和Docker Builder（需要装插件）。 Maven中Local Maven Repository选择default即可，但是在Maven软件中，需要修改maven(你的maven路径)/conf/setting.xml中的修改local repository标签，例如以下地址。因为权限问题，如果把本地仓库放入root目录下，会报错。 1&lt;localRepository&gt;/var/.m2/repository&lt;/localRepository&gt; Docker Builder设置。首先安装Docker Builder插件，设置Docker URL为以下二选一。本地docker可以选择以下两种的任意一种。 12unix:///var/run/docker.sock#连接本地dockertcp://xxx.x.xx.xx:2375#连接远程docker 点Test Connection验证链接是否正确。连接远程出错请参看本文“访问远程Docker”这一小节，本地出现错误请修改Jenkins所在服务器中/var/run/docker.sock权限，最简单粗暴的是chmod 777 /var/run/docker.sock。 控制Docker控制Docker流程可以用脚本，也可以用Execute Docker Command插件，在设置好Docker Builder后，很容易设置Execute Docker Command，下面用脚本演示。 1234567docker stop $(docker ps -aq --filter=&#x27;name=yang&#x27; | paste -sd &quot;|&quot; -) #停止名为yang的容器docker rm $(docker ps -aq --filter=&#x27;name=yang&#x27; | paste -sd &quot;|&quot; -) #删除名为yang的容器docker build -t oppdocker:$BUILD_NUMBER . #创建相应镜像，注意后面有个.docker create --name yang-p 4000:8080 yangdocker:$BUILD_NUMBER #创建容器docker tag yangdocker:$BUILD_NUMBER 10.0.210.148:5000/yangdocker:$BUILD_NUMBER #标记容器docker push 10.0.210.148:5000/yangdocker:$BUILD_NUMBER #标记容器到远程仓库docker start yang #启动容器 PepelinePepeline事实上Groovy脚本，先放放，稍后写","categories":[],"tags":[{"name":"devops","slug":"devops","permalink":"https://jevonyang.github.io/tags/devops/"}]},{"title":"Git简明教程","slug":"Git简明教程","date":"2017-07-20T09:02:58.000Z","updated":"2021-10-22T02:22:56.176Z","comments":true,"path":"2017/07/20/Git简明教程/","link":"","permalink":"https://jevonyang.github.io/2017/07/20/Git%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B/","excerpt":"","text":"一、Git的安装1. Windows下安装请于https://git-scm.com/downloads 下载exe文件，安装即可。完成后，在命令行下输入命令： git --version 出现git版本号，即为安装成功。 若命令后出现错误，请检查环境变量，请加入git的环境变量，例如C:\\Program Files\\Git\\cmd;。 2. 类Unix环境下安装在Linux/类Unix环境下，利用仓库安装较为快捷，并且大多数Linux仓库中有git源。 例1、Debian/Ubuntu apt-get install git 例2、Fedora yum install git 更多请参见https://git-scm.com/download/linux 二、Git的命令行操作1.Git的本地配置在安装后，还需配置用户的姓名及Email，配置命令如下： git config --global user.name &quot;Your Name&quot; git config --global user.email &quot;email@example.com&quot; 这样就可以让git服务器识别自己的身份。在第一次操作远程仓库的时候，会提示 The authenticity of host &#39;github.com (xx.xx.xx.xx)&#39; can&#39;t be established. RSA key fingerprint is xx.xx.xx.xx.xx. Are you sure you want to continue connecting (yes/no)? 大意为，对方服务器是谁谁谁，是否连接。输入yes即可。 2.SSH免密登录 Windows在git bash中输入如下命令，然后一路回车。 ssh-keygen -t rsa -C &quot;email@example.com&quot; 在C:\\Users\\xxx(你的用户名).ssh下产生两个文件：id_rsa和id_rsa.pub，其中pub文件即为你的公钥，讲公钥提交到服务器，即可免密登录。 3.克隆命令从远程仓库克隆需要所需的源代码命令 git clone git@[ip或者域名]:[远程仓库路径] 例如：git clone git@10.192.10.40:/usr/repositories/opp.git 4.远程仓库配置从远程仓库克隆下来源代码，我们不仅仅满足于此。与远程仓库相关的操作还很多，我们不能总是输入一大推链接，于是我们将仓库有个“别名”。 git remote add origin git@10.192.10.40:/usr/repositories/opp.git 其中origin即为所谓的别名，当我们需要更换远程仓库地址的时候，可以使用如下命令 git remote set-url origin git@github.com:JevonYang/example.git 5.提交改动git作为分布式代码管理系统，代码的改变需要几个步骤，一般的来说，需要先改变本地的仓库的代码，再讲本地仓库的代码推送到远程仓库。 改变本地仓库代码，首先需要添加改动文件，再进行提交： git add filename 或者 git add . //添加改动文件 git commit -m &quot;some comments&quot; //提交改动 另外，我们可以通过一下命令查看，状态及相应记录 git status//查看提交状态 git log//查看提交记录 前者增加一个文件的改动，后者增加全部文件改动，注意后面的英文符号点不要忘记。在git commit命令之后，会出现确认文件选项，即删除改动文件前#号保存即为提交完成。 6.推送到远程仓库接下来，我们尝试将文件推送到远程仓库，使用如下命令： git push [远程仓库] [分支名称] 例如：git push -u origin master 如果刚刚没有改动文件的话，远程仓库是不会改变的。 7.分支操作在很多时候，我们需要用到分支操作，在分支操作上进行一些改动。 git checkout -b dev //建立并切换到分支上 git push -u origin dev //将新建分支推送到远端 git branch//查看分支 8.合并分支在开发某功能后，需要将以开发的内容合并到主干上。 git checkout master //切换到主干 git merge --no-ff dev //和Dev分支合并 9.解决冲突有操作就有冲突，git也为我们提供了良好的解决冲突方法。我们假设目前有两个分支master和dev，在master中曾经有过修复bug的改动，而dev中有增加新的feature改动，目前希望将两个分支合并，这样显然会出现冲突。 git merget --no-ff dev Git用&lt;&lt;&lt;&lt;&lt;&lt;&lt;，=======，&gt;&gt;&gt;&gt;&gt;&gt;&gt;标记出不同分支的内容，当我们做出选择后，保存文件。 git add . git commit -m &quot;some comments&quot; git push -u origin master 在合并后，我们选择在此保存文件、提交文件，进而完成合并。 10.暂存功能在dev开发某功能时，急需改动主干分支上的bug，于是我们需要将dev开发的内容暂存起来。 git stash//此时branch在dev上，把已开发内容进行暂存 git checkout master//切换到主干分支，进行bug修复 git checkout -b issuexx//创建分支，进行修复 git checkout dev //切回开发分支 git stash list //查看暂存功能列表 git stash apply //从暂存区域恢复 11.标签操作增删标签 git tag v1.0//为当前版本添加标签 git tag -d v0.1 //删除标签 增加过往标签 git log --pretty=oneline --abbrev-commit//查看提交历史 git tag v0.9 cc17032 //为commit id为cc17032的提交添加标签 git tag -a v0.1 -m &quot;some comments&quot; cc17032 //添加标签、备注 查看标签 git tag//查看所有标签 git show v1.0//查看标签信息 推送标签到远端 git push origin v1.0//推送某一标签 git push origin --tags//推送全部标签 三、MyEclipse egit插件使用git插件仅仅是git功能的延伸，下文以MyEclipse为例说明。 1.Git插件安装 下载MyEcilpse Git插件例如：http://download.csdn.net/detail/get_set/7688939 在MyEcilpse安装目录dropins文件夹新建egit文件夹，例如C:\\Users\\xxx(你的用户名)\\AppData\\Local\\MyEclipse\\MyEclipse 10\\dropins\\egit 放入解压后的文件，启动MyEclipse即可 2.从远端导入项目 File-&gt;Import-&gt;Git-&gt;Projects from Git-&gt;URI-&gt; 输入远程仓库URI，例如&#x67;&#105;&#116;&#x40;&#x31;&#x30;&#x2e;&#x31;&#x39;&#50;&#x2e;&#49;&#48;&#x2e;&#x34;&#48;:/usr/repositories/opp.git IDE会自动填写host以及repository path Connection中填写通讯协议ssh，端口22 Authentication中填写git服务器git账号及相应密码 四、Git服务器搭建1.远端安装Git下文以CentOS举例说明 远端利用yum源安装git， yum -y install git 远端添加账户: groupadd git useradd git -g git passwd git #参数是用户名 2.远端建立仓库 切换到git账户 su - git 创建远程仓库，并会有相应提示，即为远程仓库的位置 mkdir test.git cd test.git git init --bare //创建裸仓 Initialized existing Git repository in /home/repositories/test.git/ 3.SSH免密码登录设置 配置ssh功能，以及密钥文件位置 vim /etc/ssh/sshd_config 在该文件中，可以看到以下三项被#号注释，去掉#号，打开注释。 #RSAAuthentication yes #PubkeyAuthentication yes #AuthorizedKeysFile .ssh/authorized_keys 在git目录下创建.ssh/authorized_keys文件用于放置密钥，可以用以下命令也可以手动粘贴 cat your_rsa_key.pub&gt;&gt;/home/git/.ssh/authorized_keys 参考文献GIT官网1 Git教程-廖雪峰的官方网站2 GIT教程-易百教程3 CentOS7下git服务器端搭建4","categories":[],"tags":[{"name":"git","slug":"git","permalink":"https://jevonyang.github.io/tags/git/"}]}],"categories":[],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://jevonyang.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"reactive, spring webflux","slug":"reactive-spring-webflux","permalink":"https://jevonyang.github.io/tags/reactive-spring-webflux/"},{"name":"callback","slug":"callback","permalink":"https://jevonyang.github.io/tags/callback/"},{"name":"java","slug":"java","permalink":"https://jevonyang.github.io/tags/java/"},{"name":"spring security","slug":"spring-security","permalink":"https://jevonyang.github.io/tags/spring-security/"},{"name":"spring cloud","slug":"spring-cloud","permalink":"https://jevonyang.github.io/tags/spring-cloud/"},{"name":"devops","slug":"devops","permalink":"https://jevonyang.github.io/tags/devops/"},{"name":"git","slug":"git","permalink":"https://jevonyang.github.io/tags/git/"}]}